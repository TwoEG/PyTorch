{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils import data as D\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import torchsummary\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "validation_ratio = 0.1\n",
    "random_seed = 10\n",
    "initial_lr = 0.1\n",
    "num_epoch = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "        #transforms.Resize(32),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "transform_validation = transforms.Compose([\n",
    "        #transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        #transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_validation)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bn_relu_conv(nn.Module):\n",
    "    def __init__(self, nin, nout, kernel_size, stride, padding, bias=False):\n",
    "        super().__init__()\n",
    "        self.batch_norm = nn.BatchNorm2d(nin)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.conv = nn.Conv2d(nin, nout, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.batch_norm(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleneck_layer(nn.Sequential):\n",
    "    def __init__(self, nin, growth_rate, drop_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.add_module('conv_1x1', bn_relu_conv(nin=nin, nout=growth_rate*4, kernel_size=1, stride=1, padding=0, bias=False))\n",
    "        self.add_module('conv_3x3', bn_relu_conv(nin=growth_rate*4, nout=growth_rate, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = super().forward(x)\n",
    "        if(self.drop_rate > 0):\n",
    "            out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition_layer(nn.Sequential):\n",
    "    def __init__(self, nin, theta=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.add_module('conv_1x1', bn_relu_conv(nin=nin, nout=int(nin*theta), kernel_size=1, stride=1, padding=0, bias=False))\n",
    "        self.add_module('avg_pool_2x2', nn.AvgPool2d(kernel_size=2, stride=2, padding=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Sequential):\n",
    "    def __init__(self, nin, num_bottleneck_layers, growth_rate, drop_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        for i in range(num_bottleneck_layers):\n",
    "            nin_layer = nin + growth_rate * i\n",
    "            self.add_module(f'bottleneck_layer_{nin_layer}', bottleneck_layer(nin=nin_layer, growth_rate=growth_rate, drop_rate=drop_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense-BC Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growth_rate=12, num_layers=100, theta=0.5, drop_rate=0.2, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert (num_layers - 4) % 6 == 0\n",
    "        \n",
    "        # (num_layers-4)//6 \n",
    "        num_bottleneck_layers = (num_layers - 4) // 6\n",
    "        \n",
    "        # 32 x 32 x 3 --> 32 x 32 x (growth_rate*2)\n",
    "        self.dense_init = nn.Conv2d(3, growth_rate*2, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        \n",
    "        # 32 x 32 x (growth_rate*2) --> 32 x 32 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_1 = DenseBlock(nin=growth_rate*2, num_bottleneck_layers=num_bottleneck_layers, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        \n",
    "         # 32 x 32 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)] --> 16 x 16 x [(growth_rate*2) + (growth_rate * num_bottleneck_layers)]*theta\n",
    "        nin_transition_layer_1 = (growth_rate*2) + (growth_rate * num_bottleneck_layers) \n",
    "        self.transition_layer_1 = Transition_layer(nin=nin_transition_layer_1, theta=theta)\n",
    "        \n",
    "        # 16 x 16 x nin_transition_layer_1*theta --> 16 x 16 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_2 = DenseBlock(nin=int(nin_transition_layer_1*theta), num_bottleneck_layers=num_bottleneck_layers, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "\n",
    "        # 16 x 16 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)] --> 8 x 8 x [nin_transition_layer_1*theta + (growth_rate * num_bottleneck_layers)]*theta\n",
    "        nin_transition_layer_2 = int(nin_transition_layer_1*theta) + (growth_rate * num_bottleneck_layers) \n",
    "        self.transition_layer_2 = Transition_layer(nin=nin_transition_layer_2, theta=theta)\n",
    "        \n",
    "        # 8 x 8 x nin_transition_layer_2*theta --> 8 x 8 x [nin_transition_layer_2*theta + (growth_rate * num_bottleneck_layers)]\n",
    "        self.dense_block_3 = DenseBlock(nin=int(nin_transition_layer_2*theta), num_bottleneck_layers=num_bottleneck_layers, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        \n",
    "        nin_fc_layer = int(nin_transition_layer_2*theta) + (growth_rate * num_bottleneck_layers)\n",
    "        \n",
    "        # [nin_transition_layer_2*theta + (growth_rate * num_bottleneck_layers)] --> num_classes\n",
    "        self.fc_layer = nn.Linear(nin_fc_layer, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dense_init_output = self.dense_init(x)\n",
    "        \n",
    "        dense_block_1_output = self.dense_block_1(dense_init_output)\n",
    "        transition_layer_1_output = self.transition_layer_1(dense_block_1_output)\n",
    "        \n",
    "        dense_block_2_output = self.dense_block_2(transition_layer_1_output)\n",
    "        transition_layer_2_output = self.transition_layer_2(dense_block_2_output)\n",
    "        \n",
    "        dense_block_3_output = self.dense_block_3(transition_layer_2_output)\n",
    "        \n",
    "        global_avg_pool_output = F.adaptive_avg_pool2d(dense_block_3_output, (1, 1))                \n",
    "        global_avg_pool_output_flat = global_avg_pool_output.view(global_avg_pool_output.size(0), -1)\n",
    "\n",
    "        output = self.fc_layer(global_avg_pool_output_flat)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNetBC_100_12():\n",
    "    return DenseNet(growth_rate=12, num_layers=100, theta=0.5, drop_rate=0.2, num_classes=10)\n",
    "\n",
    "def DenseNetBC_250_24():\n",
    "    return DenseNet(growth_rate=24, num_layers=250, theta=0.5, drop_rate=0.2, num_classes=10)\n",
    "\n",
    "def DenseNetBC_190_40():\n",
    "    return DenseNet(growth_rate=40, num_layers=190, theta=0.5, drop_rate=0.2, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             672\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "      bn_relu_conv-5           [-1, 48, 32, 32]               0\n",
      "       BatchNorm2d-6           [-1, 48, 32, 32]              96\n",
      "              ReLU-7           [-1, 48, 32, 32]               0\n",
      "            Conv2d-8           [-1, 12, 32, 32]           5,184\n",
      "      bn_relu_conv-9           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-10           [-1, 36, 32, 32]              72\n",
      "             ReLU-11           [-1, 36, 32, 32]               0\n",
      "           Conv2d-12           [-1, 48, 32, 32]           1,728\n",
      "     bn_relu_conv-13           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-14           [-1, 48, 32, 32]              96\n",
      "             ReLU-15           [-1, 48, 32, 32]               0\n",
      "           Conv2d-16           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-17           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-18           [-1, 48, 32, 32]              96\n",
      "             ReLU-19           [-1, 48, 32, 32]               0\n",
      "           Conv2d-20           [-1, 48, 32, 32]           2,304\n",
      "     bn_relu_conv-21           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-22           [-1, 48, 32, 32]              96\n",
      "             ReLU-23           [-1, 48, 32, 32]               0\n",
      "           Conv2d-24           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-25           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-26           [-1, 60, 32, 32]             120\n",
      "             ReLU-27           [-1, 60, 32, 32]               0\n",
      "           Conv2d-28           [-1, 48, 32, 32]           2,880\n",
      "     bn_relu_conv-29           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 48, 32, 32]              96\n",
      "             ReLU-31           [-1, 48, 32, 32]               0\n",
      "           Conv2d-32           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-33           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-34           [-1, 72, 32, 32]             144\n",
      "             ReLU-35           [-1, 72, 32, 32]               0\n",
      "           Conv2d-36           [-1, 48, 32, 32]           3,456\n",
      "     bn_relu_conv-37           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-38           [-1, 48, 32, 32]              96\n",
      "             ReLU-39           [-1, 48, 32, 32]               0\n",
      "           Conv2d-40           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-41           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-42           [-1, 84, 32, 32]             168\n",
      "             ReLU-43           [-1, 84, 32, 32]               0\n",
      "           Conv2d-44           [-1, 48, 32, 32]           4,032\n",
      "     bn_relu_conv-45           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-46           [-1, 48, 32, 32]              96\n",
      "             ReLU-47           [-1, 48, 32, 32]               0\n",
      "           Conv2d-48           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-49           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-50           [-1, 96, 32, 32]             192\n",
      "             ReLU-51           [-1, 96, 32, 32]               0\n",
      "           Conv2d-52           [-1, 48, 32, 32]           4,608\n",
      "     bn_relu_conv-53           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-54           [-1, 48, 32, 32]              96\n",
      "             ReLU-55           [-1, 48, 32, 32]               0\n",
      "           Conv2d-56           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-57           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-58          [-1, 108, 32, 32]             216\n",
      "             ReLU-59          [-1, 108, 32, 32]               0\n",
      "           Conv2d-60           [-1, 48, 32, 32]           5,184\n",
      "     bn_relu_conv-61           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-62           [-1, 48, 32, 32]              96\n",
      "             ReLU-63           [-1, 48, 32, 32]               0\n",
      "           Conv2d-64           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-65           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-66          [-1, 120, 32, 32]             240\n",
      "             ReLU-67          [-1, 120, 32, 32]               0\n",
      "           Conv2d-68           [-1, 48, 32, 32]           5,760\n",
      "     bn_relu_conv-69           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-70           [-1, 48, 32, 32]              96\n",
      "             ReLU-71           [-1, 48, 32, 32]               0\n",
      "           Conv2d-72           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-73           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-74          [-1, 132, 32, 32]             264\n",
      "             ReLU-75          [-1, 132, 32, 32]               0\n",
      "           Conv2d-76           [-1, 48, 32, 32]           6,336\n",
      "     bn_relu_conv-77           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-78           [-1, 48, 32, 32]              96\n",
      "             ReLU-79           [-1, 48, 32, 32]               0\n",
      "           Conv2d-80           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-81           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-82          [-1, 144, 32, 32]             288\n",
      "             ReLU-83          [-1, 144, 32, 32]               0\n",
      "           Conv2d-84           [-1, 48, 32, 32]           6,912\n",
      "     bn_relu_conv-85           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-86           [-1, 48, 32, 32]              96\n",
      "             ReLU-87           [-1, 48, 32, 32]               0\n",
      "           Conv2d-88           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-89           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-90          [-1, 156, 32, 32]             312\n",
      "             ReLU-91          [-1, 156, 32, 32]               0\n",
      "           Conv2d-92           [-1, 48, 32, 32]           7,488\n",
      "     bn_relu_conv-93           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-94           [-1, 48, 32, 32]              96\n",
      "             ReLU-95           [-1, 48, 32, 32]               0\n",
      "           Conv2d-96           [-1, 12, 32, 32]           5,184\n",
      "     bn_relu_conv-97           [-1, 12, 32, 32]               0\n",
      "      BatchNorm2d-98          [-1, 168, 32, 32]             336\n",
      "             ReLU-99          [-1, 168, 32, 32]               0\n",
      "          Conv2d-100           [-1, 48, 32, 32]           8,064\n",
      "    bn_relu_conv-101           [-1, 48, 32, 32]               0\n",
      "     BatchNorm2d-102           [-1, 48, 32, 32]              96\n",
      "            ReLU-103           [-1, 48, 32, 32]               0\n",
      "          Conv2d-104           [-1, 12, 32, 32]           5,184\n",
      "    bn_relu_conv-105           [-1, 12, 32, 32]               0\n",
      "     BatchNorm2d-106          [-1, 180, 32, 32]             360\n",
      "            ReLU-107          [-1, 180, 32, 32]               0\n",
      "          Conv2d-108           [-1, 48, 32, 32]           8,640\n",
      "    bn_relu_conv-109           [-1, 48, 32, 32]               0\n",
      "     BatchNorm2d-110           [-1, 48, 32, 32]              96\n",
      "            ReLU-111           [-1, 48, 32, 32]               0\n",
      "          Conv2d-112           [-1, 12, 32, 32]           5,184\n",
      "    bn_relu_conv-113           [-1, 12, 32, 32]               0\n",
      "     BatchNorm2d-114          [-1, 192, 32, 32]             384\n",
      "            ReLU-115          [-1, 192, 32, 32]               0\n",
      "          Conv2d-116           [-1, 48, 32, 32]           9,216\n",
      "    bn_relu_conv-117           [-1, 48, 32, 32]               0\n",
      "     BatchNorm2d-118           [-1, 48, 32, 32]              96\n",
      "            ReLU-119           [-1, 48, 32, 32]               0\n",
      "          Conv2d-120           [-1, 12, 32, 32]           5,184\n",
      "    bn_relu_conv-121           [-1, 12, 32, 32]               0\n",
      "     BatchNorm2d-122          [-1, 204, 32, 32]             408\n",
      "            ReLU-123          [-1, 204, 32, 32]               0\n",
      "          Conv2d-124           [-1, 48, 32, 32]           9,792\n",
      "    bn_relu_conv-125           [-1, 48, 32, 32]               0\n",
      "     BatchNorm2d-126           [-1, 48, 32, 32]              96\n",
      "            ReLU-127           [-1, 48, 32, 32]               0\n",
      "          Conv2d-128           [-1, 12, 32, 32]           5,184\n",
      "    bn_relu_conv-129           [-1, 12, 32, 32]               0\n",
      "     BatchNorm2d-130          [-1, 216, 32, 32]             432\n",
      "            ReLU-131          [-1, 216, 32, 32]               0\n",
      "          Conv2d-132          [-1, 108, 32, 32]          23,328\n",
      "    bn_relu_conv-133          [-1, 108, 32, 32]               0\n",
      "       AvgPool2d-134          [-1, 108, 16, 16]               0\n",
      "     BatchNorm2d-135          [-1, 108, 16, 16]             216\n",
      "            ReLU-136          [-1, 108, 16, 16]               0\n",
      "          Conv2d-137           [-1, 48, 16, 16]           5,184\n",
      "    bn_relu_conv-138           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-139           [-1, 48, 16, 16]              96\n",
      "            ReLU-140           [-1, 48, 16, 16]               0\n",
      "          Conv2d-141           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-142           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-143          [-1, 120, 16, 16]             240\n",
      "            ReLU-144          [-1, 120, 16, 16]               0\n",
      "          Conv2d-145           [-1, 48, 16, 16]           5,760\n",
      "    bn_relu_conv-146           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-147           [-1, 48, 16, 16]              96\n",
      "            ReLU-148           [-1, 48, 16, 16]               0\n",
      "          Conv2d-149           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-150           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-151          [-1, 132, 16, 16]             264\n",
      "            ReLU-152          [-1, 132, 16, 16]               0\n",
      "          Conv2d-153           [-1, 48, 16, 16]           6,336\n",
      "    bn_relu_conv-154           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-155           [-1, 48, 16, 16]              96\n",
      "            ReLU-156           [-1, 48, 16, 16]               0\n",
      "          Conv2d-157           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-158           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-159          [-1, 144, 16, 16]             288\n",
      "            ReLU-160          [-1, 144, 16, 16]               0\n",
      "          Conv2d-161           [-1, 48, 16, 16]           6,912\n",
      "    bn_relu_conv-162           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-163           [-1, 48, 16, 16]              96\n",
      "            ReLU-164           [-1, 48, 16, 16]               0\n",
      "          Conv2d-165           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-166           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-167          [-1, 156, 16, 16]             312\n",
      "            ReLU-168          [-1, 156, 16, 16]               0\n",
      "          Conv2d-169           [-1, 48, 16, 16]           7,488\n",
      "    bn_relu_conv-170           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-171           [-1, 48, 16, 16]              96\n",
      "            ReLU-172           [-1, 48, 16, 16]               0\n",
      "          Conv2d-173           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-174           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-175          [-1, 168, 16, 16]             336\n",
      "            ReLU-176          [-1, 168, 16, 16]               0\n",
      "          Conv2d-177           [-1, 48, 16, 16]           8,064\n",
      "    bn_relu_conv-178           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-179           [-1, 48, 16, 16]              96\n",
      "            ReLU-180           [-1, 48, 16, 16]               0\n",
      "          Conv2d-181           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-182           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-183          [-1, 180, 16, 16]             360\n",
      "            ReLU-184          [-1, 180, 16, 16]               0\n",
      "          Conv2d-185           [-1, 48, 16, 16]           8,640\n",
      "    bn_relu_conv-186           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-187           [-1, 48, 16, 16]              96\n",
      "            ReLU-188           [-1, 48, 16, 16]               0\n",
      "          Conv2d-189           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-190           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-191          [-1, 192, 16, 16]             384\n",
      "            ReLU-192          [-1, 192, 16, 16]               0\n",
      "          Conv2d-193           [-1, 48, 16, 16]           9,216\n",
      "    bn_relu_conv-194           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-195           [-1, 48, 16, 16]              96\n",
      "            ReLU-196           [-1, 48, 16, 16]               0\n",
      "          Conv2d-197           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-198           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-199          [-1, 204, 16, 16]             408\n",
      "            ReLU-200          [-1, 204, 16, 16]               0\n",
      "          Conv2d-201           [-1, 48, 16, 16]           9,792\n",
      "    bn_relu_conv-202           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-203           [-1, 48, 16, 16]              96\n",
      "            ReLU-204           [-1, 48, 16, 16]               0\n",
      "          Conv2d-205           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-206           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-207          [-1, 216, 16, 16]             432\n",
      "            ReLU-208          [-1, 216, 16, 16]               0\n",
      "          Conv2d-209           [-1, 48, 16, 16]          10,368\n",
      "    bn_relu_conv-210           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-211           [-1, 48, 16, 16]              96\n",
      "            ReLU-212           [-1, 48, 16, 16]               0\n",
      "          Conv2d-213           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-214           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-215          [-1, 228, 16, 16]             456\n",
      "            ReLU-216          [-1, 228, 16, 16]               0\n",
      "          Conv2d-217           [-1, 48, 16, 16]          10,944\n",
      "    bn_relu_conv-218           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-219           [-1, 48, 16, 16]              96\n",
      "            ReLU-220           [-1, 48, 16, 16]               0\n",
      "          Conv2d-221           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-222           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-223          [-1, 240, 16, 16]             480\n",
      "            ReLU-224          [-1, 240, 16, 16]               0\n",
      "          Conv2d-225           [-1, 48, 16, 16]          11,520\n",
      "    bn_relu_conv-226           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-227           [-1, 48, 16, 16]              96\n",
      "            ReLU-228           [-1, 48, 16, 16]               0\n",
      "          Conv2d-229           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-230           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-231          [-1, 252, 16, 16]             504\n",
      "            ReLU-232          [-1, 252, 16, 16]               0\n",
      "          Conv2d-233           [-1, 48, 16, 16]          12,096\n",
      "    bn_relu_conv-234           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-235           [-1, 48, 16, 16]              96\n",
      "            ReLU-236           [-1, 48, 16, 16]               0\n",
      "          Conv2d-237           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-238           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-239          [-1, 264, 16, 16]             528\n",
      "            ReLU-240          [-1, 264, 16, 16]               0\n",
      "          Conv2d-241           [-1, 48, 16, 16]          12,672\n",
      "    bn_relu_conv-242           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-243           [-1, 48, 16, 16]              96\n",
      "            ReLU-244           [-1, 48, 16, 16]               0\n",
      "          Conv2d-245           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-246           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-247          [-1, 276, 16, 16]             552\n",
      "            ReLU-248          [-1, 276, 16, 16]               0\n",
      "          Conv2d-249           [-1, 48, 16, 16]          13,248\n",
      "    bn_relu_conv-250           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-251           [-1, 48, 16, 16]              96\n",
      "            ReLU-252           [-1, 48, 16, 16]               0\n",
      "          Conv2d-253           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-254           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-255          [-1, 288, 16, 16]             576\n",
      "            ReLU-256          [-1, 288, 16, 16]               0\n",
      "          Conv2d-257           [-1, 48, 16, 16]          13,824\n",
      "    bn_relu_conv-258           [-1, 48, 16, 16]               0\n",
      "     BatchNorm2d-259           [-1, 48, 16, 16]              96\n",
      "            ReLU-260           [-1, 48, 16, 16]               0\n",
      "          Conv2d-261           [-1, 12, 16, 16]           5,184\n",
      "    bn_relu_conv-262           [-1, 12, 16, 16]               0\n",
      "     BatchNorm2d-263          [-1, 300, 16, 16]             600\n",
      "            ReLU-264          [-1, 300, 16, 16]               0\n",
      "          Conv2d-265          [-1, 150, 16, 16]          45,000\n",
      "    bn_relu_conv-266          [-1, 150, 16, 16]               0\n",
      "       AvgPool2d-267            [-1, 150, 8, 8]               0\n",
      "     BatchNorm2d-268            [-1, 150, 8, 8]             300\n",
      "            ReLU-269            [-1, 150, 8, 8]               0\n",
      "          Conv2d-270             [-1, 48, 8, 8]           7,200\n",
      "    bn_relu_conv-271             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-272             [-1, 48, 8, 8]              96\n",
      "            ReLU-273             [-1, 48, 8, 8]               0\n",
      "          Conv2d-274             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-275             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-276            [-1, 162, 8, 8]             324\n",
      "            ReLU-277            [-1, 162, 8, 8]               0\n",
      "          Conv2d-278             [-1, 48, 8, 8]           7,776\n",
      "    bn_relu_conv-279             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-280             [-1, 48, 8, 8]              96\n",
      "            ReLU-281             [-1, 48, 8, 8]               0\n",
      "          Conv2d-282             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-283             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-284            [-1, 174, 8, 8]             348\n",
      "            ReLU-285            [-1, 174, 8, 8]               0\n",
      "          Conv2d-286             [-1, 48, 8, 8]           8,352\n",
      "    bn_relu_conv-287             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-288             [-1, 48, 8, 8]              96\n",
      "            ReLU-289             [-1, 48, 8, 8]               0\n",
      "          Conv2d-290             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-291             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-292            [-1, 186, 8, 8]             372\n",
      "            ReLU-293            [-1, 186, 8, 8]               0\n",
      "          Conv2d-294             [-1, 48, 8, 8]           8,928\n",
      "    bn_relu_conv-295             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-296             [-1, 48, 8, 8]              96\n",
      "            ReLU-297             [-1, 48, 8, 8]               0\n",
      "          Conv2d-298             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-299             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-300            [-1, 198, 8, 8]             396\n",
      "            ReLU-301            [-1, 198, 8, 8]               0\n",
      "          Conv2d-302             [-1, 48, 8, 8]           9,504\n",
      "    bn_relu_conv-303             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-304             [-1, 48, 8, 8]              96\n",
      "            ReLU-305             [-1, 48, 8, 8]               0\n",
      "          Conv2d-306             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-307             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-308            [-1, 210, 8, 8]             420\n",
      "            ReLU-309            [-1, 210, 8, 8]               0\n",
      "          Conv2d-310             [-1, 48, 8, 8]          10,080\n",
      "    bn_relu_conv-311             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-312             [-1, 48, 8, 8]              96\n",
      "            ReLU-313             [-1, 48, 8, 8]               0\n",
      "          Conv2d-314             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-315             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-316            [-1, 222, 8, 8]             444\n",
      "            ReLU-317            [-1, 222, 8, 8]               0\n",
      "          Conv2d-318             [-1, 48, 8, 8]          10,656\n",
      "    bn_relu_conv-319             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-320             [-1, 48, 8, 8]              96\n",
      "            ReLU-321             [-1, 48, 8, 8]               0\n",
      "          Conv2d-322             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-323             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-324            [-1, 234, 8, 8]             468\n",
      "            ReLU-325            [-1, 234, 8, 8]               0\n",
      "          Conv2d-326             [-1, 48, 8, 8]          11,232\n",
      "    bn_relu_conv-327             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-328             [-1, 48, 8, 8]              96\n",
      "            ReLU-329             [-1, 48, 8, 8]               0\n",
      "          Conv2d-330             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-331             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-332            [-1, 246, 8, 8]             492\n",
      "            ReLU-333            [-1, 246, 8, 8]               0\n",
      "          Conv2d-334             [-1, 48, 8, 8]          11,808\n",
      "    bn_relu_conv-335             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-336             [-1, 48, 8, 8]              96\n",
      "            ReLU-337             [-1, 48, 8, 8]               0\n",
      "          Conv2d-338             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-339             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-340            [-1, 258, 8, 8]             516\n",
      "            ReLU-341            [-1, 258, 8, 8]               0\n",
      "          Conv2d-342             [-1, 48, 8, 8]          12,384\n",
      "    bn_relu_conv-343             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-344             [-1, 48, 8, 8]              96\n",
      "            ReLU-345             [-1, 48, 8, 8]               0\n",
      "          Conv2d-346             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-347             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-348            [-1, 270, 8, 8]             540\n",
      "            ReLU-349            [-1, 270, 8, 8]               0\n",
      "          Conv2d-350             [-1, 48, 8, 8]          12,960\n",
      "    bn_relu_conv-351             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-352             [-1, 48, 8, 8]              96\n",
      "            ReLU-353             [-1, 48, 8, 8]               0\n",
      "          Conv2d-354             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-355             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-356            [-1, 282, 8, 8]             564\n",
      "            ReLU-357            [-1, 282, 8, 8]               0\n",
      "          Conv2d-358             [-1, 48, 8, 8]          13,536\n",
      "    bn_relu_conv-359             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-360             [-1, 48, 8, 8]              96\n",
      "            ReLU-361             [-1, 48, 8, 8]               0\n",
      "          Conv2d-362             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-363             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-364            [-1, 294, 8, 8]             588\n",
      "            ReLU-365            [-1, 294, 8, 8]               0\n",
      "          Conv2d-366             [-1, 48, 8, 8]          14,112\n",
      "    bn_relu_conv-367             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-368             [-1, 48, 8, 8]              96\n",
      "            ReLU-369             [-1, 48, 8, 8]               0\n",
      "          Conv2d-370             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-371             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-372            [-1, 306, 8, 8]             612\n",
      "            ReLU-373            [-1, 306, 8, 8]               0\n",
      "          Conv2d-374             [-1, 48, 8, 8]          14,688\n",
      "    bn_relu_conv-375             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-376             [-1, 48, 8, 8]              96\n",
      "            ReLU-377             [-1, 48, 8, 8]               0\n",
      "          Conv2d-378             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-379             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-380            [-1, 318, 8, 8]             636\n",
      "            ReLU-381            [-1, 318, 8, 8]               0\n",
      "          Conv2d-382             [-1, 48, 8, 8]          15,264\n",
      "    bn_relu_conv-383             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-384             [-1, 48, 8, 8]              96\n",
      "            ReLU-385             [-1, 48, 8, 8]               0\n",
      "          Conv2d-386             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-387             [-1, 12, 8, 8]               0\n",
      "     BatchNorm2d-388            [-1, 330, 8, 8]             660\n",
      "            ReLU-389            [-1, 330, 8, 8]               0\n",
      "          Conv2d-390             [-1, 48, 8, 8]          15,840\n",
      "    bn_relu_conv-391             [-1, 48, 8, 8]               0\n",
      "     BatchNorm2d-392             [-1, 48, 8, 8]              96\n",
      "            ReLU-393             [-1, 48, 8, 8]               0\n",
      "          Conv2d-394             [-1, 12, 8, 8]           5,184\n",
      "    bn_relu_conv-395             [-1, 12, 8, 8]               0\n",
      "          Linear-396                   [-1, 10]           3,430\n",
      "================================================================\n",
      "Total params: 768,502\n",
      "Trainable params: 768,502\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 87.35\n",
      "Params size (MB): 2.93\n",
      "Estimated Total Size (MB): 90.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = DenseNetBC_100_12()\n",
    "net.to(device)\n",
    "torchsummary.summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  6400/50000] loss: 2.0273851\n",
      "[1, 12800/50000] loss: 1.8639786\n",
      "[1, 19200/50000] loss: 1.7695985\n",
      "[1, 25600/50000] loss: 1.6576472\n",
      "[1, 32000/50000] loss: 1.5770954\n",
      "[1, 38400/50000] loss: 1.4769986\n",
      "[1, 44800/50000] loss: 1.4208205\n",
      "[1 epoch] Accuracy of the network on the validation images: 45 %\n",
      "[2,  6400/50000] loss: 1.3157876\n",
      "[2, 12800/50000] loss: 1.2727262\n",
      "[2, 19200/50000] loss: 1.2225172\n",
      "[2, 25600/50000] loss: 1.1589898\n",
      "[2, 32000/50000] loss: 1.1334126\n",
      "[2, 38400/50000] loss: 1.1148165\n",
      "[2, 44800/50000] loss: 1.0815089\n",
      "[2 epoch] Accuracy of the network on the validation images: 50 %\n",
      "[3,  6400/50000] loss: 1.0414704\n",
      "[3, 12800/50000] loss: 0.9967530\n",
      "[3, 19200/50000] loss: 0.9774588\n",
      "[3, 25600/50000] loss: 0.9623412\n",
      "[3, 32000/50000] loss: 0.9440707\n",
      "[3, 38400/50000] loss: 0.9487243\n",
      "[3, 44800/50000] loss: 0.9033741\n",
      "[3 epoch] Accuracy of the network on the validation images: 63 %\n",
      "[4,  6400/50000] loss: 0.9045988\n",
      "[4, 12800/50000] loss: 0.8743138\n",
      "[4, 19200/50000] loss: 0.8718294\n",
      "[4, 25600/50000] loss: 0.8331856\n",
      "[4, 32000/50000] loss: 0.8324093\n",
      "[4, 38400/50000] loss: 0.8071457\n",
      "[4, 44800/50000] loss: 0.8167190\n",
      "[4 epoch] Accuracy of the network on the validation images: 64 %\n",
      "[5,  6400/50000] loss: 0.7741901\n",
      "[5, 12800/50000] loss: 0.7493767\n",
      "[5, 19200/50000] loss: 0.7561766\n",
      "[5, 25600/50000] loss: 0.7475250\n",
      "[5, 32000/50000] loss: 0.7415251\n",
      "[5, 38400/50000] loss: 0.7074912\n",
      "[5, 44800/50000] loss: 0.6887381\n",
      "[5 epoch] Accuracy of the network on the validation images: 68 %\n",
      "[6,  6400/50000] loss: 0.6923470\n",
      "[6, 12800/50000] loss: 0.6769645\n",
      "[6, 19200/50000] loss: 0.6689496\n",
      "[6, 25600/50000] loss: 0.6692259\n",
      "[6, 32000/50000] loss: 0.6582224\n",
      "[6, 38400/50000] loss: 0.6613523\n",
      "[6, 44800/50000] loss: 0.6453169\n",
      "[6 epoch] Accuracy of the network on the validation images: 73 %\n",
      "[7,  6400/50000] loss: 0.6080916\n",
      "[7, 12800/50000] loss: 0.6174130\n",
      "[7, 19200/50000] loss: 0.6167587\n",
      "[7, 25600/50000] loss: 0.6003040\n",
      "[7, 32000/50000] loss: 0.6087930\n",
      "[7, 38400/50000] loss: 0.5930050\n",
      "[7, 44800/50000] loss: 0.5805030\n",
      "[7 epoch] Accuracy of the network on the validation images: 76 %\n",
      "[8,  6400/50000] loss: 0.5905382\n",
      "[8, 12800/50000] loss: 0.5556325\n",
      "[8, 19200/50000] loss: 0.5619206\n",
      "[8, 25600/50000] loss: 0.5420266\n",
      "[8, 32000/50000] loss: 0.5649917\n",
      "[8, 38400/50000] loss: 0.5496166\n",
      "[8, 44800/50000] loss: 0.5320090\n",
      "[8 epoch] Accuracy of the network on the validation images: 77 %\n",
      "[9,  6400/50000] loss: 0.6024573\n",
      "[9, 12800/50000] loss: 0.5251765\n",
      "[9, 19200/50000] loss: 0.5085991\n",
      "[9, 25600/50000] loss: 0.4985815\n",
      "[9, 32000/50000] loss: 0.5253452\n",
      "[9, 38400/50000] loss: 0.5164805\n",
      "[9, 44800/50000] loss: 0.5044417\n",
      "[9 epoch] Accuracy of the network on the validation images: 77 %\n",
      "[10,  6400/50000] loss: 0.4796584\n",
      "[10, 12800/50000] loss: 0.4802712\n",
      "[10, 19200/50000] loss: 0.4909678\n",
      "[10, 25600/50000] loss: 0.4885524\n",
      "[10, 32000/50000] loss: 0.4810914\n",
      "[10, 38400/50000] loss: 0.4749317\n",
      "[10, 44800/50000] loss: 0.4842223\n",
      "[10 epoch] Accuracy of the network on the validation images: 78 %\n",
      "[11,  6400/50000] loss: 0.4468796\n",
      "[11, 12800/50000] loss: 0.4652599\n",
      "[11, 19200/50000] loss: 0.4495042\n",
      "[11, 25600/50000] loss: 0.4593125\n",
      "[11, 32000/50000] loss: 0.4272188\n",
      "[11, 38400/50000] loss: 0.4542586\n",
      "[11, 44800/50000] loss: 0.4685990\n",
      "[11 epoch] Accuracy of the network on the validation images: 80 %\n",
      "[12,  6400/50000] loss: 0.4514339\n",
      "[12, 12800/50000] loss: 0.4288896\n",
      "[12, 19200/50000] loss: 0.4197749\n",
      "[12, 25600/50000] loss: 0.4259816\n",
      "[12, 32000/50000] loss: 0.4312486\n",
      "[12, 38400/50000] loss: 0.4358176\n",
      "[12, 44800/50000] loss: 0.4321659\n",
      "[12 epoch] Accuracy of the network on the validation images: 80 %\n",
      "[13,  6400/50000] loss: 0.4136870\n",
      "[13, 12800/50000] loss: 0.4123328\n",
      "[13, 19200/50000] loss: 0.3992523\n",
      "[13, 25600/50000] loss: 0.4173410\n",
      "[13, 32000/50000] loss: 0.3932258\n",
      "[13, 38400/50000] loss: 0.4110824\n",
      "[13, 44800/50000] loss: 0.4142421\n",
      "[13 epoch] Accuracy of the network on the validation images: 79 %\n",
      "[14,  6400/50000] loss: 0.3629654\n",
      "[14, 12800/50000] loss: 0.4009603\n",
      "[14, 19200/50000] loss: 0.3822759\n",
      "[14, 25600/50000] loss: 0.3913871\n",
      "[14, 32000/50000] loss: 0.3860721\n",
      "[14, 38400/50000] loss: 0.3733799\n",
      "[14, 44800/50000] loss: 0.3948453\n",
      "[14 epoch] Accuracy of the network on the validation images: 81 %\n",
      "[15,  6400/50000] loss: 0.3700934\n",
      "[15, 12800/50000] loss: 0.3543009\n",
      "[15, 19200/50000] loss: 0.3481328\n",
      "[15, 25600/50000] loss: 0.3641704\n",
      "[15, 32000/50000] loss: 0.3650382\n",
      "[15, 38400/50000] loss: 0.3771402\n",
      "[15, 44800/50000] loss: 0.3948954\n",
      "[15 epoch] Accuracy of the network on the validation images: 81 %\n",
      "[16,  6400/50000] loss: 0.3606436\n",
      "[16, 12800/50000] loss: 0.3646683\n",
      "[16, 19200/50000] loss: 0.3424477\n",
      "[16, 25600/50000] loss: 0.3658921\n",
      "[16, 32000/50000] loss: 0.3375533\n",
      "[16, 38400/50000] loss: 0.3552536\n",
      "[16, 44800/50000] loss: 0.3633593\n",
      "[16 epoch] Accuracy of the network on the validation images: 81 %\n",
      "[17,  6400/50000] loss: 0.3852655\n",
      "[17, 12800/50000] loss: 0.3422540\n",
      "[17, 19200/50000] loss: 0.3410479\n",
      "[17, 25600/50000] loss: 0.3365605\n",
      "[17, 32000/50000] loss: 0.3511095\n",
      "[17, 38400/50000] loss: 0.3599419\n",
      "[17, 44800/50000] loss: 0.3491446\n",
      "[17 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[18,  6400/50000] loss: 0.3229414\n",
      "[18, 12800/50000] loss: 0.3355935\n",
      "[18, 19200/50000] loss: 0.3325017\n",
      "[18, 25600/50000] loss: 0.3239487\n",
      "[18, 32000/50000] loss: 0.3356810\n",
      "[18, 38400/50000] loss: 0.3426025\n",
      "[18, 44800/50000] loss: 0.3289102\n",
      "[18 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[19,  6400/50000] loss: 0.3051864\n",
      "[19, 12800/50000] loss: 0.3165640\n",
      "[19, 19200/50000] loss: 0.3356933\n",
      "[19, 25600/50000] loss: 0.3072659\n",
      "[19, 32000/50000] loss: 0.3350535\n",
      "[19, 38400/50000] loss: 0.3031940\n",
      "[19, 44800/50000] loss: 0.3278305\n",
      "[19 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[20,  6400/50000] loss: 0.2872134\n",
      "[20, 12800/50000] loss: 0.2860400\n",
      "[20, 19200/50000] loss: 0.3034969\n",
      "[20, 25600/50000] loss: 0.2919636\n",
      "[20, 32000/50000] loss: 0.3117023\n",
      "[20, 38400/50000] loss: 0.3241591\n",
      "[20, 44800/50000] loss: 0.2982239\n",
      "[20 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[21,  6400/50000] loss: 0.3072275\n",
      "[21, 12800/50000] loss: 0.2832165\n",
      "[21, 19200/50000] loss: 0.3116545\n",
      "[21, 25600/50000] loss: 0.2905312\n",
      "[21, 32000/50000] loss: 0.2894663\n",
      "[21, 38400/50000] loss: 0.3137347\n",
      "[21, 44800/50000] loss: 0.3103429\n",
      "[21 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[22,  6400/50000] loss: 0.2760301\n",
      "[22, 12800/50000] loss: 0.2612693\n",
      "[22, 19200/50000] loss: 0.2904618\n",
      "[22, 25600/50000] loss: 0.3020847\n",
      "[22, 32000/50000] loss: 0.2854664\n",
      "[22, 38400/50000] loss: 0.2908129\n",
      "[22, 44800/50000] loss: 0.3102792\n",
      "[22 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[23,  6400/50000] loss: 0.2841579\n",
      "[23, 12800/50000] loss: 0.2651490\n",
      "[23, 19200/50000] loss: 0.2796606\n",
      "[23, 25600/50000] loss: 0.2758037\n",
      "[23, 32000/50000] loss: 0.2738523\n",
      "[23, 38400/50000] loss: 0.2970499\n",
      "[23, 44800/50000] loss: 0.2780295\n",
      "[23 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[24,  6400/50000] loss: 0.2818651\n",
      "[24, 12800/50000] loss: 0.2441617\n",
      "[24, 19200/50000] loss: 0.2470838\n",
      "[24, 25600/50000] loss: 0.2874836\n",
      "[24, 32000/50000] loss: 0.2706586\n",
      "[24, 38400/50000] loss: 0.2675197\n",
      "[24, 44800/50000] loss: 0.2764832\n",
      "[24 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[25,  6400/50000] loss: 0.2484450\n",
      "[25, 12800/50000] loss: 0.2389158\n",
      "[25, 19200/50000] loss: 0.2581771\n",
      "[25, 25600/50000] loss: 0.2672009\n",
      "[25, 32000/50000] loss: 0.2593582\n",
      "[25, 38400/50000] loss: 0.2656175\n",
      "[25, 44800/50000] loss: 0.2635107\n",
      "[25 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[26,  6400/50000] loss: 0.2655214\n",
      "[26, 12800/50000] loss: 0.2554852\n",
      "[26, 19200/50000] loss: 0.2592273\n",
      "[26, 25600/50000] loss: 0.2400429\n",
      "[26, 32000/50000] loss: 0.2468281\n",
      "[26, 38400/50000] loss: 0.2699610\n",
      "[26, 44800/50000] loss: 0.2546665\n",
      "[26 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[27,  6400/50000] loss: 0.2440446\n",
      "[27, 12800/50000] loss: 0.2534777\n",
      "[27, 19200/50000] loss: 0.2344770\n",
      "[27, 25600/50000] loss: 0.2340203\n",
      "[27, 32000/50000] loss: 0.2311570\n",
      "[27, 38400/50000] loss: 0.2472509\n",
      "[27, 44800/50000] loss: 0.2371773\n",
      "[27 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[28,  6400/50000] loss: 0.2473867\n",
      "[28, 12800/50000] loss: 0.2268496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 19200/50000] loss: 0.2316839\n",
      "[28, 25600/50000] loss: 0.2400822\n",
      "[28, 32000/50000] loss: 0.2445799\n",
      "[28, 38400/50000] loss: 0.2387697\n",
      "[28, 44800/50000] loss: 0.2336230\n",
      "[28 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[29,  6400/50000] loss: 0.2266293\n",
      "[29, 12800/50000] loss: 0.2404615\n",
      "[29, 19200/50000] loss: 0.2262727\n",
      "[29, 25600/50000] loss: 0.2357835\n",
      "[29, 32000/50000] loss: 0.2348641\n",
      "[29, 38400/50000] loss: 0.2458966\n",
      "[29, 44800/50000] loss: 0.2271600\n",
      "[29 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[30,  6400/50000] loss: 0.2255780\n",
      "[30, 12800/50000] loss: 0.2249512\n",
      "[30, 19200/50000] loss: 0.2413984\n",
      "[30, 25600/50000] loss: 0.2201385\n",
      "[30, 32000/50000] loss: 0.2361741\n",
      "[30, 38400/50000] loss: 0.2245094\n",
      "[30, 44800/50000] loss: 0.2179522\n",
      "[30 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[31,  6400/50000] loss: 0.1705236\n",
      "[31, 12800/50000] loss: 0.1465425\n",
      "[31, 19200/50000] loss: 0.1485045\n",
      "[31, 25600/50000] loss: 0.1415243\n",
      "[31, 32000/50000] loss: 0.1279312\n",
      "[31, 38400/50000] loss: 0.1262275\n",
      "[31, 44800/50000] loss: 0.1279706\n",
      "[31 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[32,  6400/50000] loss: 0.1257185\n",
      "[32, 12800/50000] loss: 0.1189771\n",
      "[32, 19200/50000] loss: 0.1192985\n",
      "[32, 25600/50000] loss: 0.1129916\n",
      "[32, 32000/50000] loss: 0.1164839\n",
      "[32, 38400/50000] loss: 0.1143145\n",
      "[32, 44800/50000] loss: 0.1223172\n",
      "[32 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[33,  6400/50000] loss: 0.1137683\n",
      "[33, 12800/50000] loss: 0.1050624\n",
      "[33, 19200/50000] loss: 0.1083747\n",
      "[33, 25600/50000] loss: 0.1038464\n",
      "[33, 32000/50000] loss: 0.1058022\n",
      "[33, 38400/50000] loss: 0.1121017\n",
      "[33, 44800/50000] loss: 0.1133326\n",
      "[33 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[34,  6400/50000] loss: 0.1051946\n",
      "[34, 12800/50000] loss: 0.1124632\n",
      "[34, 19200/50000] loss: 0.1099482\n",
      "[34, 25600/50000] loss: 0.1030175\n",
      "[34, 32000/50000] loss: 0.1053613\n",
      "[34, 38400/50000] loss: 0.1075486\n",
      "[34, 44800/50000] loss: 0.0931823\n",
      "[34 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[35,  6400/50000] loss: 0.1046595\n",
      "[35, 12800/50000] loss: 0.0939378\n",
      "[35, 19200/50000] loss: 0.1045167\n",
      "[35, 25600/50000] loss: 0.0955328\n",
      "[35, 32000/50000] loss: 0.1007092\n",
      "[35, 38400/50000] loss: 0.0997931\n",
      "[35, 44800/50000] loss: 0.0967030\n",
      "[35 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[36,  6400/50000] loss: 0.0942788\n",
      "[36, 12800/50000] loss: 0.0940755\n",
      "[36, 19200/50000] loss: 0.0992329\n",
      "[36, 25600/50000] loss: 0.0948879\n",
      "[36, 32000/50000] loss: 0.0978639\n",
      "[36, 38400/50000] loss: 0.0944919\n",
      "[36, 44800/50000] loss: 0.0913691\n",
      "[36 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[37,  6400/50000] loss: 0.0872366\n",
      "[37, 12800/50000] loss: 0.0916773\n",
      "[37, 19200/50000] loss: 0.0863164\n",
      "[37, 25600/50000] loss: 0.0902676\n",
      "[37, 32000/50000] loss: 0.0891114\n",
      "[37, 38400/50000] loss: 0.0849230\n",
      "[37, 44800/50000] loss: 0.0932016\n",
      "[37 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[38,  6400/50000] loss: 0.0927439\n",
      "[38, 12800/50000] loss: 0.0881903\n",
      "[38, 19200/50000] loss: 0.0897529\n",
      "[38, 25600/50000] loss: 0.0895347\n",
      "[38, 32000/50000] loss: 0.0869125\n",
      "[38, 38400/50000] loss: 0.0888599\n",
      "[38, 44800/50000] loss: 0.0854972\n",
      "[38 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[39,  6400/50000] loss: 0.0821540\n",
      "[39, 12800/50000] loss: 0.0974815\n",
      "[39, 19200/50000] loss: 0.0831805\n",
      "[39, 25600/50000] loss: 0.0802352\n",
      "[39, 32000/50000] loss: 0.0883813\n",
      "[39, 38400/50000] loss: 0.0874507\n",
      "[39, 44800/50000] loss: 0.0973625\n",
      "[39 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[40,  6400/50000] loss: 0.0854766\n",
      "[40, 12800/50000] loss: 0.0789008\n",
      "[40, 19200/50000] loss: 0.0864599\n",
      "[40, 25600/50000] loss: 0.0887900\n",
      "[40, 32000/50000] loss: 0.0794759\n",
      "[40, 38400/50000] loss: 0.0792309\n",
      "[40, 44800/50000] loss: 0.0905702\n",
      "[40 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[41,  6400/50000] loss: 0.0837918\n",
      "[41, 12800/50000] loss: 0.0769580\n",
      "[41, 19200/50000] loss: 0.0799358\n",
      "[41, 25600/50000] loss: 0.0828990\n",
      "[41, 32000/50000] loss: 0.0805416\n",
      "[41, 38400/50000] loss: 0.0870852\n",
      "[41, 44800/50000] loss: 0.0779756\n",
      "[41 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[42,  6400/50000] loss: 0.0774347\n",
      "[42, 12800/50000] loss: 0.0714984\n",
      "[42, 19200/50000] loss: 0.0842337\n",
      "[42, 25600/50000] loss: 0.0805850\n",
      "[42, 32000/50000] loss: 0.0967041\n",
      "[42, 38400/50000] loss: 0.0786481\n",
      "[42, 44800/50000] loss: 0.0834867\n",
      "[42 epoch] Accuracy of the network on the validation images: 87 %\n",
      "[43,  6400/50000] loss: 0.0819961\n",
      "[43, 12800/50000] loss: 0.0745175\n",
      "[43, 19200/50000] loss: 0.0807544\n",
      "[43, 25600/50000] loss: 0.0792447\n",
      "[43, 32000/50000] loss: 0.0779299\n",
      "[43, 38400/50000] loss: 0.0689897\n",
      "[43, 44800/50000] loss: 0.0860474\n",
      "[43 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[44,  6400/50000] loss: 0.0745272\n",
      "[44, 12800/50000] loss: 0.0801343\n",
      "[44, 19200/50000] loss: 0.0759729\n",
      "[44, 25600/50000] loss: 0.0822560\n",
      "[44, 32000/50000] loss: 0.0769387\n",
      "[44, 38400/50000] loss: 0.0721552\n",
      "[44, 44800/50000] loss: 0.0812917\n",
      "[44 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[45,  6400/50000] loss: 0.0725986\n",
      "[45, 12800/50000] loss: 0.0769028\n",
      "[45, 19200/50000] loss: 0.0789677\n",
      "[45, 25600/50000] loss: 0.0731435\n",
      "[45, 32000/50000] loss: 0.0717029\n",
      "[45, 38400/50000] loss: 0.0802754\n",
      "[45, 44800/50000] loss: 0.0771735\n",
      "[45 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[46,  6400/50000] loss: 0.0702457\n",
      "[46, 12800/50000] loss: 0.0673137\n",
      "[46, 19200/50000] loss: 0.0691798\n",
      "[46, 25600/50000] loss: 0.0727389\n",
      "[46, 32000/50000] loss: 0.0711174\n",
      "[46, 38400/50000] loss: 0.0646019\n",
      "[46, 44800/50000] loss: 0.0692326\n",
      "[46 epoch] Accuracy of the network on the validation images: 89 %\n",
      "[47,  6400/50000] loss: 0.0726917\n",
      "[47, 12800/50000] loss: 0.0628460\n",
      "[47, 19200/50000] loss: 0.0639687\n",
      "[47, 25600/50000] loss: 0.0614964\n",
      "[47, 32000/50000] loss: 0.0717220\n",
      "[47, 38400/50000] loss: 0.0705923\n",
      "[47, 44800/50000] loss: 0.0717372\n",
      "[47 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[48,  6400/50000] loss: 0.0668921\n",
      "[48, 12800/50000] loss: 0.0659773\n",
      "[48, 19200/50000] loss: 0.0754756\n",
      "[48, 25600/50000] loss: 0.0683329\n",
      "[48, 32000/50000] loss: 0.0614066\n",
      "[48, 38400/50000] loss: 0.0679116\n",
      "[48, 44800/50000] loss: 0.0694369\n",
      "[48 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[49,  6400/50000] loss: 0.0719055\n",
      "[49, 12800/50000] loss: 0.0653253\n",
      "[49, 19200/50000] loss: 0.0651417\n",
      "[49, 25600/50000] loss: 0.0706702\n",
      "[49, 32000/50000] loss: 0.0670346\n",
      "[49, 38400/50000] loss: 0.0625139\n",
      "[49, 44800/50000] loss: 0.0676443\n",
      "[49 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[50,  6400/50000] loss: 0.0633787\n",
      "[50, 12800/50000] loss: 0.0660864\n",
      "[50, 19200/50000] loss: 0.0604837\n",
      "[50, 25600/50000] loss: 0.0649968\n",
      "[50, 32000/50000] loss: 0.0578468\n",
      "[50, 38400/50000] loss: 0.0697729\n",
      "[50, 44800/50000] loss: 0.0605570\n",
      "[50 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[51,  6400/50000] loss: 0.0579980\n",
      "[51, 12800/50000] loss: 0.0687823\n",
      "[51, 19200/50000] loss: 0.0676799\n",
      "[51, 25600/50000] loss: 0.0677653\n",
      "[51, 32000/50000] loss: 0.0669809\n",
      "[51, 38400/50000] loss: 0.0697920\n",
      "[51, 44800/50000] loss: 0.0556133\n",
      "[51 epoch] Accuracy of the network on the validation images: 89 %\n",
      "[52,  6400/50000] loss: 0.0584263\n",
      "[52, 12800/50000] loss: 0.0631084\n",
      "[52, 19200/50000] loss: 0.0673468\n",
      "[52, 25600/50000] loss: 0.0631594\n",
      "[52, 32000/50000] loss: 0.0666279\n",
      "[52, 38400/50000] loss: 0.0626008\n",
      "[52, 44800/50000] loss: 0.0646925\n",
      "[52 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[53,  6400/50000] loss: 0.0680157\n",
      "[53, 12800/50000] loss: 0.0608469\n",
      "[53, 19200/50000] loss: 0.0645481\n",
      "[53, 25600/50000] loss: 0.0659658\n",
      "[53, 32000/50000] loss: 0.0688318\n",
      "[53, 38400/50000] loss: 0.0579501\n",
      "[53, 44800/50000] loss: 0.0635229\n",
      "[53 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[54,  6400/50000] loss: 0.0659909\n",
      "[54, 12800/50000] loss: 0.0689042\n",
      "[54, 19200/50000] loss: 0.0675165\n",
      "[54, 25600/50000] loss: 0.0653250\n",
      "[54, 32000/50000] loss: 0.0676997\n",
      "[54, 38400/50000] loss: 0.0680976\n",
      "[54, 44800/50000] loss: 0.0668723\n",
      "[54 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[55,  6400/50000] loss: 0.0638449\n",
      "[55, 12800/50000] loss: 0.0675846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55, 19200/50000] loss: 0.0602541\n",
      "[55, 25600/50000] loss: 0.0625588\n",
      "[55, 32000/50000] loss: 0.0645695\n",
      "[55, 38400/50000] loss: 0.0598875\n",
      "[55, 44800/50000] loss: 0.0656702\n",
      "[55 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[56,  6400/50000] loss: 0.0669931\n",
      "[56, 12800/50000] loss: 0.0574971\n",
      "[56, 19200/50000] loss: 0.0673085\n",
      "[56, 25600/50000] loss: 0.0614022\n",
      "[56, 32000/50000] loss: 0.0633363\n",
      "[56, 38400/50000] loss: 0.0608405\n",
      "[56, 44800/50000] loss: 0.0581804\n",
      "[56 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[57,  6400/50000] loss: 0.0677162\n",
      "[57, 12800/50000] loss: 0.0665425\n",
      "[57, 19200/50000] loss: 0.0653303\n",
      "[57, 25600/50000] loss: 0.0634381\n",
      "[57, 32000/50000] loss: 0.0603526\n",
      "[57, 38400/50000] loss: 0.0627632\n",
      "[57, 44800/50000] loss: 0.0581740\n",
      "[57 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[58,  6400/50000] loss: 0.0680557\n",
      "[58, 12800/50000] loss: 0.0622794\n",
      "[58, 19200/50000] loss: 0.0571273\n",
      "[58, 25600/50000] loss: 0.0639166\n",
      "[58, 32000/50000] loss: 0.0652949\n",
      "[58, 38400/50000] loss: 0.0655999\n",
      "[58, 44800/50000] loss: 0.0627586\n",
      "[58 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[59,  6400/50000] loss: 0.0614026\n",
      "[59, 12800/50000] loss: 0.0570198\n",
      "[59, 19200/50000] loss: 0.0584948\n",
      "[59, 25600/50000] loss: 0.0624772\n",
      "[59, 32000/50000] loss: 0.0579295\n",
      "[59, 38400/50000] loss: 0.0685247\n",
      "[59, 44800/50000] loss: 0.0601093\n",
      "[59 epoch] Accuracy of the network on the validation images: 88 %\n",
      "[60,  6400/50000] loss: 0.0600170\n",
      "[60, 12800/50000] loss: 0.0552330\n",
      "[60, 19200/50000] loss: 0.0626492\n",
      "[60, 25600/50000] loss: 0.0630397\n",
      "[60, 32000/50000] loss: 0.0644641\n",
      "[60, 38400/50000] loss: 0.0615043\n",
      "[60, 44800/50000] loss: 0.0597833\n",
      "[60 epoch] Accuracy of the network on the validation images: 88 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9)\n",
    "lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[int(num_epoch * 0.5), int(num_epoch * 0.75)], gamma=0.1, last_epoch=-1)\n",
    "\n",
    "for epoch in range(num_epoch):  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        show_period = 100\n",
    "        if i % show_period == show_period-1:    # print every \"show_period\" mini-batches\n",
    "            print('[%d, %5d/50000] loss: %.7f' %\n",
    "                  (epoch + 1, (i + 1)*batch_size, running_loss / show_period))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    lr_scheduler.step()\n",
    "        \n",
    "        \n",
    "    # validation part\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(valid_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n",
    "          (epoch + 1, 100 * correct / total)\n",
    "         )\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of plane : 91 %\n",
      "Accuracy of   car : 93 %\n",
      "Accuracy of  bird : 79 %\n",
      "Accuracy of   cat : 80 %\n",
      "Accuracy of  deer : 86 %\n",
      "Accuracy of   dog : 80 %\n",
      "Accuracy of  frog : 92 %\n",
      "Accuracy of horse : 90 %\n",
      "Accuracy of  ship : 93 %\n",
      "Accuracy of truck : 91 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "                \n",
    "        for i in range(labels.shape[0]):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))            \n",
    "            \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
